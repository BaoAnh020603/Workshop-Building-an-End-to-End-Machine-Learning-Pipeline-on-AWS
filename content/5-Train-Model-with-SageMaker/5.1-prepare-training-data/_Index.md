+++
title = "Preparing Input Data for SageMaker"
date = 2025
weight = 1
chapter = false
pre = "<b>5.1 </b>"
+++

Before we start training a machine learning model with **Amazon SageMaker**, we need to **check and organize the pre-processed data** from Lambda. This is an important step to ensure the training process is accurate and efficient.

---

### ğŸ§  The role of data in the pipeline

Data is the â€œfuelâ€ of the ML model. The quality and structure of the input data will directly affect:

- ğŸ“Š **Training performance** â€“ the model learns better when the data has been cleaned.
- ğŸ” **Prediction accuracy** â€“ clean and properly formatted data helps the model predict more accurately.
- âš™ï¸ **Pipeline Automation** â€“ SageMaker requires a consistent data structure to create training jobs.

---

#### ğŸª„ 1. Check the processed data on S3

Go to **Amazon S3** in the AWS Management Console to verify the input data from Lambda:

1. Select the bucket you created in section **3 â€“ Create S3 Bucket for Data Storage**.

2. Open the `processed/` folder â€“ this is where Lambda saved the pre-processed data.

3. Check if the CSV or Parquet file exists (e.g. `data_processed.csv`).

ğŸ“¸ Example folder structure:
~~~
ml-pipeline-bucket/
â”œâ”€ raw/
â”‚ â””â”€ data.csv
â””â”€ processed/
â””â”€ data_processed.csv
~~~
![create-lambda.png](/images/5-Configure-API-Gateway/5.1-prepare-training-data/5.1.png)
![create-lambda.png](/images/5-Configure-API-Gateway/5.1-prepare-training-data/5.2.png)
![create-lambda.png](/images/5-Configure-API-Gateway/5.1-prepare-training-data/5.3.png)
{{% notice tip %}}
ğŸ’¡ The data in the `processed/` folder is the input that SageMaker uses in the next model training step.
{{% /notice %}}

---

#### ğŸ§± 2. Organize data properly in SageMaker

SageMaker expects the input data to be in a specific folder in S3, for example:
~~~
s3://ml-pipeline-bucket/processed/train/
s3://ml-pipeline-bucket/processed/validation/
~~~

You can organize the data as follows:

- **train/** â€“ contains data used to train the model (~80%)
- **validation/** â€“ contains data used to evaluate the model (~20%)

ğŸ“Œ For example:
~~~
processed/
â”œâ”€ train/
â”‚ â””â”€ train.csv
â””â”€ validation/
â””â”€ val.csv
~~~
![create-lambda.png](/images/5-Configure-API-Gateway/5.1-prepare-training-data/5.4.png)

---

#### ğŸ› ï¸ 3. Update S3 Access Permissions for SageMaker

Ensure the SageMaker IAM Role has access to the bucket containing the data:

- `s3:GetObject`
- `s3:ListBucket`
- `s3:PutObject` *(if write results are needed)*

{{% notice warning %}}
âš ï¸ If SageMaker does not have permission to read data from the S3 bucket, the training job will **fail immediately**.
{{% /notice %}}

---

#### ğŸ” 4. Check the data format

- SageMaker supports **CSV**, **Parquet**, or **RecordIO** formats.

- If using CSV, ensure:
- There are **headers** describing the columns.
- There are no null values â€‹â€‹or formatting errors.
- Numeric features have been normalized (if needed).

Example of a standard `train.csv` file:

```csv
feature1,feature2,feature3,label
0.21,0.75,0.11,1
0.56,0.22,0.65,0
0.34,0.12,0.88,1
```
![create-lambda.png](/images/5-Configure-API-Gateway/5.1-prepare-training-data/5.5.png)
![create-lambda.png](/images/5-Configure-API-Gateway/5.1-prepare-training-data/5.6.png)
#### âœ… Done

You have completed preparing the input data for SageMaker:

- ğŸ“ The data has been preprocessed and saved to the processed/ folder on S3
- ğŸ—‚ï¸ The data has been split into train/ and validation/
- ğŸ” The IAM Role has the necessary access
- ğŸ§¹ The data format has been verified