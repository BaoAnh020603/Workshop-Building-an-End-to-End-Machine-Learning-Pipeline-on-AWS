+++
title = "XÃ¢y dá»±ng Lambda Function vÃ  REST API cho Inference"
date = 2025
weight = 7
chapter = false
pre = "<b>7. </b>"
+++

![lambda-inference-overview.png](/images/7.0.png)

Trong pháº§n nÃ y, chÃºng ta sáº½ triá»ƒn khai má»™t **Lambda function** Ä‘á»ƒ gá»i mÃ´ hÃ¬nh Ä‘Ã£ triá»ƒn khai trÃªn SageMaker Endpoint (bÆ°á»›c 6) vÃ  táº¡o má»™t **REST API Gateway** Ä‘á»ƒ client cÃ³ thá»ƒ gá»­i yÃªu cáº§u inference. ÄÃ¢y lÃ  máº¯t xÃ­ch quan trá»ng giÃºp biáº¿n mÃ´ hÃ¬nh ML thÃ nh má»™t dá»‹ch vá»¥ dá»± Ä‘oÃ¡n hoÃ n chá»‰nh.

---

### ğŸ¯ Má»¥c tiÃªu
- Táº¡o Lambda function gá»i SageMaker Endpoint Ä‘á»ƒ xá»­ lÃ½ inference.  
- Káº¿t ná»‘i Lambda vá»›i API Gateway Ä‘á»ƒ táº¡o REST API.  
- Kiá»ƒm tra inference tá»« Postman hoáº·c trÃ¬nh duyá»‡t.

---

#### ğŸ§  7.1 â€“ Táº¡o Lambda Function Ä‘á»ƒ gá»i SageMaker Endpoint

1. Truy cáº­p **AWS Management Console** â†’ **Lambda** â†’ **Create function**  
2. Cáº¥u hÃ¬nh:
   - **Function name**: `invoke-ml-endpoint`
   - **Runtime**: `Python 3.9`
   - **Execution role**: Chá»n role cÃ³ quyá»n gá»i SageMaker (hoáº·c táº¡o role má»›i vá»›i quyá»n `AmazonSageMakerFullAccess` vÃ  `AWSLambdaBasicExecutionRole`)

3. Nháº¥n **Create function**
![lambda-inference-overview.png](/images/7-Build-Lambda-Inference-and-API/7.1.png)
![lambda-inference-overview.png](/images/7-Build-Lambda-Inference-and-API/7.2.png)
![lambda-inference-overview.png](/images/7-Build-Lambda-Inference-and-API/7.3.png)

---

#### âœï¸ 7.2 â€“ Viáº¿t mÃ£ Lambda Ä‘á»ƒ gá»i Endpoint

Thay ná»™i dung máº·c Ä‘á»‹nh trong tab **Code** báº±ng Ä‘oáº¡n mÃ£ sau:

```python
import json
import boto3
import os

runtime = boto3.client('sagemaker-runtime')

ENDPOINT_NAME = os.environ.get('ENDPOINT_NAME', 'ml-blog-endpoint')

def lambda_handler(event, context):
    try:
        body = json.loads(event['body'])
        features = body.get('features')

        if features is None:
            return {
                "statusCode": 400,
                "body": json.dumps({"error": "Missing 'features' in request body"})
            }

        response = runtime.invoke_endpoint(
            EndpointName=ENDPOINT_NAME,
            ContentType='application/json',
            Body=json.dumps({"features": features})
        )

        result = json.loads(response['Body'].read().decode())

        return {
            "statusCode": 200,
            "headers": {"Content-Type": "application/json"},
            "body": json.dumps({"prediction": result})
        }

    except Exception as e:
        return {
            "statusCode": 500,
            "body": json.dumps({"error": str(e)})
        }
```

ğŸ“Œ Giáº£i thÃ­ch:
- ENDPOINT_NAME: tÃªn endpoint Ä‘Ã£ triá»ƒn khai á»Ÿ bÆ°á»›c 6.
- Lambda nháº­n dá»¯ liá»‡u JSON tá»« client (features), gá»i SageMaker endpoint, vÃ  tráº£ káº¿t quáº£ dá»± Ä‘oÃ¡n.

4. Trong pháº§n Configuration â†’ Environment variables, thÃªm biáº¿n:

    - Key: ENDPOINT_NAME
    - Value: ml-blog-endpoint

5. Nháº¥n Deploy Ä‘á»ƒ lÆ°u function.

#### ğŸŒ 7.3 â€“ Táº¡o REST API Gateway káº¿t ná»‘i Lambda

1. Truy cáº­p API Gateway â†’ Create API
    - Chá»n REST API â†’ Build
    - API name: InferenceAPI
    - Endpoint Type: Regional

2. Táº¡o resource /predict:
    - Trong Resources, chá»n Actions â†’ Create Resource
    - Resource name: predict
    - Resource path: /predict
    - Báº­t Enable API Gateway CORS â†’ Create Resource

3. ThÃªm phÆ°Æ¡ng thá»©c POST:
    - Chá»n /predict â†’ Actions â†’ Create Method â†’ POST
    - Integration type: Lambda Function
    - Lambda Function: invoke-ml-endpoint
    - Nháº¥n Save vÃ  xÃ¡c nháº­n quyá»n.

#### ğŸ”„ 7.4 â€“ Báº­t CORS vÃ  Triá»ƒn khai API

1. Trong Resources, chá»n Actions â†’ Enable CORS
    - Giá»¯ cáº¥u hÃ¬nh máº·c Ä‘á»‹nh vÃ  nháº¥n Enable CORS and replace existing CORS headers
2. Triá»ƒn khai API:
    - Actions â†’ Deploy API
    - Deployment stage: [New Stage] â†’ Ä‘áº·t tÃªn prod
    - Nháº¥n Deploy

ğŸ“Œ LÆ°u láº¡i Invoke URL vÃ­ dá»¥: 
~~~~
https://abc123xyz.execute-api.ap-southeast-1.amazonaws.com/prod/predict
~~~~
![lambda-inference-overview.png](/images/7-Build-Lambda-Inference-and-API/7.1.png)
![lambda-inference-overview.png](/images/7-Build-Lambda-Inference-and-API/7.2.png)
![lambda-inference-overview.png](/images/7-Build-Lambda-Inference-and-API/7.3.png)
![lambda-inference-overview.png](/images/7-Build-Lambda-Inference-and-API/7.4.png)
![lambda-inference-overview.png](/images/7-Build-Lambda-Inference-and-API/7.5.png)
![lambda-inference-overview.png](/images/7-Build-Lambda-Inference-and-API/7.6.png)
![lambda-inference-overview.png](/images/7-Build-Lambda-Inference-and-API/7.7.png)
![lambda-inference-overview.png](/images/7-Build-Lambda-Inference-and-API/7.8.png)
![lambda-inference-overview.png](/images/7-Build-Lambda-Inference-and-API/7.9.png)
![lambda-inference-overview.png](/images/7-Build-Lambda-Inference-and-API/7.10.png)
![lambda-inference-overview.png](/images/7-Build-Lambda-Inference-and-API/7.11.png)
![lambda-inference-overview.png](/images/7-Build-Lambda-Inference-and-API/7.12.png)

#### ğŸ§ª 7.5 â€“ Kiá»ƒm tra API Inference

Báº¡n cÃ³ thá»ƒ dÃ¹ng Postman hoáº·c lá»‡nh curl Ä‘á»ƒ kiá»ƒm tra:
~~~~
curl -X POST \
  https://abc123xyz.execute-api.ap-southeast-1.amazonaws.com/prod/predict \
  -H "Content-Type: application/json" \
  -d '{
    "features": [0.45, 0.12, 0.88, 0.33]
  }'
~~~~
####  âœ… Pháº£n há»“i máº«u:
~~~~
{
  "prediction": 1
}
~~~~
![lambda-inference-overview.png](/images/7-Build-Lambda-Inference-and-API/7.13.png)
#### ğŸ“Š 7.6 â€“ Ghi log vÃ  giÃ¡m sÃ¡t

- Kiá»ƒm tra log Lambda trong CloudWatch Logs â†’ giÃºp debug náº¿u xáº£y ra lá»—i.
- Theo dÃµi metric nhÆ° Invocations, 4XXError, Latency Ä‘á»ƒ Ä‘áº£m báº£o API hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh.

{{% notice tip %}}
ğŸ’¡ Báº¡n cÃ³ thá»ƒ thÃªm xÃ¡c thá»±c API báº±ng API Keys, Cognito User Pools hoáº·c IAM Auth náº¿u triá»ƒn khai trong mÃ´i trÆ°á»ng production.
{{% /notice %}}

#### âœ… HoÃ n thÃ nh

ğŸ‰ Báº¡n Ä‘Ã£ xÃ¢y dá»±ng thÃ nh cÃ´ng má»™t Lambda function Ä‘á»ƒ gá»i SageMaker Endpoint, táº¡o REST API Gateway, vÃ  kiá»ƒm tra inference thÃ nh cÃ´ng.

