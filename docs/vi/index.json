[
{
	"uri": "//localhost:1313/vi/1-introduction/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Workshop: Xây dựng một quy trình học máy toàn diện trên AWS với Lambda, API Gateway, S3, SageMaker và DynamoDB Trong Workshop này, bạn sẽ học cách xây dựng và triển khai một quy trình học máy to-end hoàn chỉnh trên AWS.\nChúng ta sẽ sử dụng AWS Lambda để tiền xử lý và suy luận, Amazon API Gateway để triển khai các API RESTful, Amazon S3 để lưu trữ dữ liệu, Amazon SageMaker để đào tạo và triển khai mô hình, Amazon DynamoDB để lưu trữ siêu dữ liệu và Amazon CloudWatch để giám sát và ghi nhật ký.\nMục tiêu Hiểu cách thiết kế và triển khai quy trình ML trên AWS từ thu thập dữ liệu thô đến triển khai mô hình. Triển khai tiền xử lý dữ liệu và suy luận mô hình với AWS Lambda. Huấn luyện và đăng ký mô hình bằng Amazon SageMaker. Triển khai các điểm cuối RESTful để suy luận bằng Amazon API Gateway. Lưu trữ siêu dữ liệu và nhật ký suy luận trong Amazon DynamoDB. Giám sát hiệu suất hệ thống bằng Amazon CloudWatch. Tìm hiểu về quản lý chi phí và các chiến lược tối ưu hóa AWS Free Tier. Yêu cầu Tài khoản AWS (Gói miễn phí: https://aws.amazon.com/free) Kỹ năng Python cơ bản (cho các hàm Lambda và tập lệnh ML) Quen thuộc với REST API và JSON Công cụ: AWS CLI, Git, Docker (tùy chọn), trình duyệt web (Tùy chọn) Postman để kiểm tra API Tổng quan về Kiến trúc Giải pháp bao gồm một số dịch vụ AWS được quản lý và không máy chủ hoạt động cùng nhau để tự động hóa quy trình làm việc ML:\n1. AWS Lambda Công dụng:\nTiền xử lý dữ liệu trước khi đào tạo (ví dụ: làm sạch, trích xuất tính năng). Chạy suy luận trên dữ liệu mới đến. Tích hợp các giai đoạn khác nhau của quy trình. Chi phí:\nTrạng thái Yêu cầu Chi phí/ngày Chi phí/tháng Gói miễn phí 1 triệu yêu cầu $0.00 $0.00 Sau gói miễn phí 100 nghìn yêu cầu ~$0.01 ~$0.30 2. Amazon API Gateway Công dụng:\nHiển thị các điểm cuối RESTful để kích hoạt các hàm Lambda và suy luận mô hình. Hoạt động như giao diện giữa máy khách và các dịch vụ phụ trợ. Chi phí:\nTrạng thái Yêu cầu Chi phí/ngày Chi phí/tháng Gói miễn phí 1 triệu yêu cầu $0.00 $0.00 Sau gói miễn phí 3 triệu yêu cầu ~$0.35 ~$10.50 3. Amazon S3 Công dụng:\nLưu trữ tập dữ liệu thô, kết quả tiền xử lý và các hiện vật mô hình. Kho dữ liệu tập trung cho quy trình làm việc ML. Chi phí:\nTrạng thái Lưu trữ Chi phí/ngày Chi phí/tháng Gói miễn phí Lưu trữ 5GB $0.00 $0.00 Sau gói miễn phí 5GB ~$0.03 ~$1.00 4. Amazon SageMaker Công dụng:\nĐào tạo và đăng ký các mô hình học máy. Lưu trữ các mô hình dưới dạng điểm cuối được quản lý để suy luận theo thời gian thực. Chi phí:\nTrạng thái Loại Chi phí/ngày Chi phí/tháng Dùng thử 250 giờ/tháng $0.00 $0.00 Sau khi hết hạn miễn phí ml.t2.medium ~$0.10 ~$3.00 5. Amazon DynamoDB Công dụng:\nLưu trữ siêu dữ liệu như phiên bản mô hình, số liệu đào tạo và nhật ký suy luận. Cung cấp quyền truy cập độ trễ thấp cho các ứng dụng không có máy chủ. Chi phí:\nTrạng thái Công suất Chi phí/ngày Chi phí/tháng Gói miễn phí 25 đơn vị đọc/ghi $0.00 $0.00 Sau gói miễn phí 10K đọc/ghi ~$0.02 ~$0.60 6. Amazon CloudWatch Công dụng:\nGiám sát nhật ký, theo dõi số liệu thực thi Lambda và cung cấp cảnh báo. Chi phí:\nThường Miễn phí cho các số liệu cơ bản. Tóm tắt chi phí Dịch vụ Chi phí (Gói miễn phí) Chi phí (Sau gói miễn phí) AWS Lambda $0.00 ~$0.30 Amazon API Gateway $0.00 ~$10.50 Amazon S3 $0.00 ~$1.00 Amazon SageMaker $0.00 ~$3.00 Amazon DynamoDB $0.00 ~$0.60 Amazon CloudWatch $0.00 ~$0.00 Tổng cộng $0.00 ~$15.40/tháng Quy trình làm việc Nhập dữ liệu – Dữ liệu thô được tải lên S3. Tiền xử lý – Hàm Lambda làm sạch và chuyển đổi dữ liệu. Đào tạo – SageMaker đào tạo mô hình và đăng ký mô hình trong sổ đăng ký mô hình. Triển khai – Mô hình được triển khai dưới dạng điểm cuối SageMaker. Suy luận – Lambda + API Gateway cung cấp dự đoán theo thời gian thực cho các ứng dụng khách. Siêu dữ liệu \u0026amp; Giám sát – DynamoDB lưu trữ siêu dữ liệu, CloudWatch giám sát nhật ký và số liệu. Kết luận Buổi workshop này hướng dẫn cách xây dựng một quy trình ML sẵn sàng cho sản xuất, có thể mở rộng hoàn toàn trên AWS bằng cách sử dụng các dịch vụ không máy chủ và được quản lý. Phương pháp này giảm thiểu chi phí vận hành, tự động mở rộng và vẫn tiết kiệm chi phí — thường là $0 trong Gói miễn phí và khoảng $15/tháng sau đó, tùy thuộc vào lưu lượng truy cập và mức sử dụng.\n"
},
{
	"uri": "//localhost:1313/vi/5-train-model-with-sagemaker/5.1-prepare-training-data/",
	"title": "Chuẩn bị dữ liệu đầu vào cho SageMaker",
	"tags": [],
	"description": "",
	"content": "Trước khi bắt đầu huấn luyện mô hình machine learning với Amazon SageMaker, chúng ta cần kiểm tra và tổ chức dữ liệu đã được tiền xử lý từ Lambda. Đây là bước quan trọng để đảm bảo quá trình huấn luyện diễn ra chính xác và hiệu quả.\n🧠 Vai trò của dữ liệu trong pipeline Dữ liệu là “nhiên liệu” của mô hình ML. Chất lượng và cấu trúc của dữ liệu đầu vào sẽ ảnh hưởng trực tiếp đến:\n📊 Hiệu suất huấn luyện – mô hình học tốt hơn khi dữ liệu đã được làm sạch. 🔎 Độ chính xác dự đoán – dữ liệu sạch và đúng định dạng giúp mô hình dự đoán chính xác hơn. ⚙️ Tự động hóa pipeline – SageMaker yêu cầu cấu trúc dữ liệu nhất quán để có thể tạo training job. 🪄 1. Kiểm tra dữ liệu đã xử lý trên S3 Truy cập Amazon S3 trong AWS Management Console để xác minh dữ liệu đầu vào từ Lambda:\nChọn bucket bạn đã tạo ở phần 3 – Create S3 Bucket for Data Storage. Mở thư mục processed/ – đây là nơi Lambda đã lưu dữ liệu sau tiền xử lý. Kiểm tra xem file CSV hoặc Parquet đã tồn tại chưa (ví dụ: data_processed.csv). 📸 Ví dụ cấu trúc thư mục:\nml-pipeline-bucket/ ├─ raw/ │ └─ data.csv └─ processed/ └─ data_processed.csv 💡 Dữ liệu trong thư mục processed/ chính là input để SageMaker sử dụng trong bước huấn luyện mô hình tiếp theo.\n🧱 2. Tổ chức dữ liệu đúng cấu trúc SageMaker SageMaker mong đợi dữ liệu đầu vào nằm trong một thư mục cụ thể trong S3, ví dụ:\ns3://ml-pipeline-bucket/processed/train/ s3://ml-pipeline-bucket/processed/validation/ Bạn có thể tổ chức dữ liệu như sau:\ntrain/ – chứa dữ liệu dùng để huấn luyện mô hình (~80%) validation/ – chứa dữ liệu dùng để đánh giá mô hình (~20%) 📌 Ví dụ:\nprocessed/ ├─ train/ │ └─ train.csv └─ validation/ └─ val.csv 🛠️ 3. Cập nhật quyền truy cập S3 cho SageMaker Đảm bảo IAM Role của SageMaker có quyền truy cập vào bucket chứa dữ liệu:\ns3:GetObject s3:ListBucket s3:PutObject (nếu cần ghi kết quả) ⚠️ Nếu SageMaker không có quyền đọc dữ liệu từ bucket S3, training job sẽ thất bại ngay lập tức.\n🔍 4. Kiểm tra định dạng dữ liệu SageMaker hỗ trợ định dạng CSV, Parquet, hoặc RecordIO. Nếu dùng CSV, đảm bảo: Có header mô tả các cột. Không có giá trị null hoặc lỗi định dạng. Các feature numeric đã được chuẩn hóa (nếu cần). Ví dụ một file train.csv chuẩn:\nfeature1,feature2,feature3,label 0.21,0.75,0.11,1 0.56,0.22,0.65,0 0.34,0.12,0.88,1 ✅ Hoàn thành Bạn đã hoàn tất việc chuẩn bị dữ liệu đầu vào cho SageMaker:\n📁 Dữ liệu đã được tiền xử lý và lưu vào thư mục processed/ trên S3 🗂️ Dữ liệu đã được phân chia thành train/ và validation/ 🔐 IAM Role đã có quyền truy cập cần thiết 🧹 Định dạng dữ liệu đã được xác minh "
},
{
	"uri": "//localhost:1313/vi/",
	"title": "Hội thảo: Xây dựng quy trình học máy toàn diện trên AWS với Lambda, API Gateway, S3, SageMaker và DynamoDB",
	"tags": [],
	"description": "",
	"content": "Hội thảo: Xây dựng quy trình học máy toàn diện trên AWS với Lambda, API Gateway, S3, SageMaker và DynamoDB Tổng quan Trong hội thảo này, bạn sẽ học cách xây dựng và triển khai quy trình học máy end-to-end trên AWS.\nChúng ta sẽ sử dụng AWS Lambda để tiền xử lý và suy luận, API Gateway để hiển thị các điểm cuối RESTful, S3 để lưu trữ dữ liệu, Amazon SageMaker để đào tạo và lưu trữ mô hình, DynamoDB để lưu trữ siêu dữ liệu và CloudWatch để giám sát và ghi nhật ký.\n🎯 Mục tiêu Hiểu cách thiết kế và triển khai một quy trình ML hoàn chỉnh trên AWS. Xây dựng và cấu hình các quy trình thu thập dữ liệu, tiền xử lý và đào tạo mô hình. Triển khai và quản lý các mô hình học máy với Amazon SageMaker. Hiển thị các điểm cuối suy luận thông qua API Gateway và Lambda. Tích hợp DynamoDB cho siêu dữ liệu mô hình và sử dụng CloudWatch để giám sát. Tìm hiểu các phương pháp hay nhất về quyền, bảo mật và tối ưu hóa chi phí. 🧰 Yêu cầu Có tài khoản AWS hiện tại (Mức miễn phí: https://aws.amazon.com/free) Có kiến ​​thức cơ bản về Python hoặc Go (cho các hàm Lambda và tập lệnh ML) Quen thuộc với API REST và JSON Công cụ: AWS CLI, Git, Docker (tùy chọn) và trình duyệt web (Tùy chọn) Postman để kiểm tra các điểm cuối suy luận 💡 Nếu bạn đã có tài khoản AWS với quyền truy cập đầy đủ, bạn có thể bỏ qua thiết lập IAM và tiếp tục xây dựng tài nguyên trực tiếp.\n📚 Mục lục Giới thiệu Kiểm tra Tài khoản và Quyền AWS Tạo Bucket S3 để Lưu trữ Dữ liệu Triển khai Hàm Xử lý Trước Lambda Đào tạo và Đăng ký Mô hình với Amazon SageMaker Triển khai Endpoint của SageMaker cho Inference Xây dựng Lambda Function và REST API cho Inference Tích hợp DynamoDB và CloudWatch Dọn dẹp tài nguyên Kết luận và những điểm chính "
},
{
	"uri": "//localhost:1313/vi/2-check-aws-account-and-permissions/",
	"title": "Check AWS Account and Permissions",
	"tags": [],
	"description": "",
	"content": " 💡 Best practice: Không dùng Root User để thao tác hằng ngày. Thay vào đó, hãy tạo IAM Role và IAM Policy với quyền tối thiểu cần thiết để Lambda, SageMaker và các dịch vụ khác truy cập vào S3, DynamoDB, CloudWatch trong pipeline của bạn.\nTrong phần này, bạn sẽ:\nKiểm tra tài khoản AWS và vùng hoạt động (Region). Tạo IAM Policy cho phép Lambda và SageMaker truy cập DynamoDB, S3, CloudWatch. Tạo IAM Role và gán cho Lambda. (Tùy chọn) tạo IAM Role cho SageMaker. Kiểm tra quyền hoạt động bằng Lambda test. 1. Kiểm tra tài khoản AWS và Region Đăng nhập vào AWS Management Console Kiểm tra Region ở góc trên bên phải (nên sử dụng us-east-1 hoặc ap-southeast-1 để đồng nhất pipeline). Nếu chưa kích hoạt IAM, vào IAM Console để bật dịch vụ. 📍 Lưu ý: Hầu hết các dịch vụ AWS hoạt động theo vùng. Nếu bạn tạo tài nguyên ở một vùng và gọi ở vùng khác, pipeline có thể không hoạt động hoặc lỗi ResourceNotFound.\n2. Tạo Custom IAM Policy Chúng ta sẽ tạo một policy để cấp quyền truy cập DynamoDB, S3, SageMaker và CloudWatch cho Lambda.\nĐiều hướng đến: IAM → Policies → Create policy Chọn tab JSON và dán nội dung sau: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;s3:GetObject\u0026#34;,\u0026#34;s3:PutObject\u0026#34;,\u0026#34;s3:ListBucket\u0026#34;], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::your-bucket-name\u0026#34;, \u0026#34;arn:aws:s3:::your-bucket-name/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;dynamodb:PutItem\u0026#34;,\u0026#34;dynamodb:UpdateItem\u0026#34;,\u0026#34;dynamodb:GetItem\u0026#34;,\u0026#34;dynamodb:Scan\u0026#34;,\u0026#34;dynamodb:Query\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-east-1:*:table/ModelMetadata\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;sagemaker:CreateTrainingJob\u0026#34;, \u0026#34;sagemaker:DescribeTrainingJob\u0026#34;, \u0026#34;sagemaker:CreateModel\u0026#34;, \u0026#34;sagemaker:CreateEndpoint\u0026#34;, \u0026#34;sagemaker:InvokeEndpoint\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [\u0026#34;logs:CreateLogGroup\u0026#34;,\u0026#34;logs:CreateLogStream\u0026#34;,\u0026#34;logs:PutLogEvents\u0026#34;], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } 🔐 Giải thích: Phân quyền DynamoDB chỉ cho phép Lambda thao tác trên bảng ModelMetadata. Phân quyền S3 giới hạn chỉ trong bucket bạn chỉ định. logs:* cần thiết để Lambda ghi log ra CloudWatch.\n⚠️ Cảnh báo: Đừng để \u0026ldquo;Resource\u0026rdquo;: \u0026ldquo;*\u0026rdquo; cho DynamoDB hoặc S3 trong môi trường production. Luôn giới hạn ARN cụ thể để tăng bảo mật.\n3. Tạo IAM Role cho Lambda Điều hướng đến: IAM → Roles → Create role Chọn AWS Service → Lambda → Next Gán policy ml-pipeline-access-policy vừa tạo. Gán thêm AWSLambdaBasicExecutionRole để cho phép ghi log. Đặt tên: lambda-ml-pipeline-role → Create role 📘 Thông tin: Role này sẽ được gán cho tất cả các Lambda functions trong pipeline, ví dụ: PreprocessLambda, InferenceLambda\u0026hellip;\n4. Gán IAM Role cho Lambda Functions Vào Lambda Console → Functions → [Tên function] → Configuration → Permissions Chọn Edit và thay đổi role thành lambda-ml-pipeline-role 📍 Lưu ý: Gán nhầm role là nguyên nhân phổ biến nhất gây lỗi AccessDenied khi Lambda truy cập DynamoDB hoặc S3.\n5. (Tùy chọn) Tạo IAM Role cho SageMaker Nếu bạn dùng SageMaker để train và deploy model: Vào IAM → Roles → Create role Chọn SageMaker Gán ml-pipeline-access-policy Đặt tên: sagemaker-ml-pipeline-role 6. Kiểm tra lại quyền và Test Lambda Vào IAM → Roles → lambda-ml-pipeline-role Đảm bảo policy đã gán đầy đủ và ARN đúng tài nguyên. Tạo Test event trong Lambda và chạy thử: { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;Preprocessing complete and metadata updated\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; } } ⚠️ Nếu nhận lỗi AccessDenied: Kiểm tra log trong CloudWatch. Xác minh region (us-east-1). Đảm bảo tên bảng DynamoDB và bucket S3 khớp với ARN trong policy.\n"
},
{
	"uri": "//localhost:1313/vi/5-train-model-with-sagemaker/5.2-create-training-job/",
	"title": "Tạo SageMaker Training Job",
	"tags": [],
	"description": "",
	"content": "Trong phần này, chúng ta sẽ khởi tạo và cấu hình một SageMaker Training Job để huấn luyện mô hình machine learning bằng dữ liệu đã được tiền xử lý từ Lambda và lưu trên S3.\n🎯 Mục tiêu Tạo Training Job trên SageMaker sử dụng dữ liệu trong S3. Cấu hình các tham số huấn luyện như container, instance type, input/output S3. Theo dõi tiến trình huấn luyện và xác minh kết quả. ⚙️ 1. Truy cập Amazon SageMaker Vào AWS Management Console → tìm và mở Amazon SageMaker. Trong thanh điều hướng bên trái, chọn Training jobs → Create training job. 📁 2. Đặt tên và cấu hình cơ bản Training job name: ml-pipeline-training-job IAM Role: Chọn role có quyền truy cập S3 và SageMaker (ví dụ: SageMakerExecutionRole). Algorithm source: Chọn Your own algorithm container nếu bạn có custom script. Hoặc chọn Built-in algorithm (ví dụ: XGBoost) để thử nghiệm nhanh. 💡 Nếu đây là lần đầu bạn thử nghiệm, nên chọn XGBoost built-in container để đơn giản hóa quá trình huấn luyện.\n📦 3. Cấu hình dữ liệu huấn luyện Trong phần Input data configuration:\nChannel name: train Input mode: File S3 location: s3://ml-pipeline-bucket/processed/train/ Thêm một channel mới cho validation:\nChannel name: validation S3 location: s3://ml-pipeline-bucket/processed/validation/ 📁 Cấu trúc S3 nên như sau:\nml-pipeline-bucket/ └─ processed/ ├─ train/ │ └─ train.csv └─ validation/ └─ val.csv ⚙️ 4. Cấu hình tài nguyên huấn luyện Instance type: ml.m5.large (hoặc chọn instance GPU nếu mô hình yêu cầu) Instance count: 1 Volume size: 10 GB Max runtime: 3600 (giới hạn 1 giờ huấn luyện) ⚠️ Chọn kích thước instance phù hợp với ngân sách. Các instance như ml.m5.large nằm trong Free Tier và đủ mạnh cho demo.\n📤 5. Đặt vị trí lưu mô hình sau huấn luyện Trong phần Output data configuration:\nS3 output path: s3://ml-pipeline-bucket/model/ SageMaker sẽ lưu file mô hình đã huấn luyện (ví dụ: model.tar.gz) tại đây.\n🧪 6. Khởi tạo Training Job Kiểm tra lại toàn bộ cấu hình. Nhấn Create training job để bắt đầu quá trình huấn luyện. 📊 Giao diện khi job đang chạy:\n🔎 7. Theo dõi tiến trình và kiểm tra kết quả Trong danh sách Training jobs, chọn job vừa tạo. Kiểm tra trạng thái: InProgress → Completed. Xem log chi tiết trong CloudWatch Logs để theo dõi quá trình huấn luyện. Sau khi hoàn tất, file mô hình sẽ được lưu ở: s3://ml-pipeline-bucket/model/model.tar.gz\nNếu job thất bại, kiểm tra lại quyền IAM và đường dẫn S3. Đảm bảo dữ liệu trong train/ và validation/ có cấu trúc và định dạng hợp lệ. ✅ Hoàn thành Bạn đã tạo thành công một SageMaker Training Job và huấn luyện mô hình sử dụng dữ liệu tiền xử lý từ Lambda.\n"
},
{
	"uri": "//localhost:1313/vi/5-train-model-with-sagemaker/5.3-register-and-manage-model/",
	"title": "Đăng ký và Quản lý Mô hình trong SageMaker Model Registry",
	"tags": [],
	"description": "",
	"content": "Trong phần này, chúng ta sẽ đăng ký mô hình đã huấn luyện vào SageMaker Model Registry để quản lý phiên bản, theo dõi metadata và phục vụ triển khai sau này. Đây là bước quan trọng giúp pipeline ML của bạn trở nên có thể lặp lại, kiểm soát phiên bản và dễ triển khai.\n🎯 Mục tiêu Đăng ký mô hình đã huấn luyện từ S3 output vào SageMaker Model Registry. Gắn metadata (phiên bản, thông tin dữ liệu, siêu tham số, metrics). Quản lý các phiên bản mô hình và trạng thái phê duyệt (Approved/Pending/Rejected). 🧠 1. Tổng quan về SageMaker Model Registry SageMaker Model Registry là một dịch vụ quản lý vòng đời mô hình (ML model lifecycle), cho phép bạn:\nLưu trữ và quản lý các phiên bản mô hình theo thời gian. Gắn thông tin mô hình như metrics, siêu tham số, dữ liệu huấn luyện. Kiểm soát quy trình phê duyệt mô hình trước khi triển khai. Tích hợp trực tiếp với SageMaker Endpoint để triển khai mô hình production. 📊 Kiến trúc sau khi thêm Model Registry:\n📁 2. Truy cập và tạo Model Package Group Vào AWS Management Console → chọn Amazon SageMaker. Trong menu bên trái, chọn Model registry → Model package groups. Nhấn Create model package group. Điền thông tin:\nName: ml-pipeline-model-group Description: “Model group for ML pipeline workshop” Nhấn Create model package group. 📤 3. Đăng ký mô hình đã huấn luyện Bây giờ chúng ta sẽ tạo một Model Package từ mô hình đã lưu sau training (model.tar.gz) trong S3.\nTrong Model registry → chọn group vừa tạo → Create model package. Cấu hình như sau: Model package name: ml-pipeline-model-v1\nModel location (S3): s3://ml-pipeline-bucket/model/model.tar.gz\nInference image URI:\nNếu dùng built-in XGBoost: chọn container có sẵn từ SageMaker.\nNếu custom: nhập ECR container image của bạn.\nIAM Role: SageMakerExecutionRole (có quyền truy cập S3 và SageMaker).\nApproval status: Pending manual approval (hoặc Approved nếu sẵn sàng triển khai).\n🧪 4. Gắn metadata \u0026amp; model metrics (tùy chọn) Bạn có thể đính kèm thông tin quan trọng để giúp nhóm ML/DevOps hiểu rõ mô hình:\nTraining dataset version: v1.0 Algorithm: XGBoost Accuracy: 0.912 Hyperparameters: learning_rate, max_depth, n_estimators Created by: Lambda Preprocessing Pipeline 📌 Điều này rất hữu ích khi bạn có nhiều mô hình và cần chọn mô hình tốt nhất để deploy.\n✅ 5. Quản lý phiên bản mô hình Mỗi lần bạn tạo một Model Package mới, nó sẽ trở thành một version trong group:\nVersion Model Name Accuracy Status Approval 1 ml-pipeline-model-v1 0.912 Completed Approved ✅ 2 ml-pipeline-model-v2 0.927 Completed Pending 🕐 📈 Bạn có thể cập nhật trạng thái mô hình từ Pending → Approved khi đã đánh giá xong.\n🔎 6. Kiểm tra mô hình đã đăng ký bằng AWS CLI (tùy chọn) Nếu muốn tự động hóa, bạn có thể đăng ký mô hình bằng CLI:\naws sagemaker create-model-package \\ --model-package-group-name ml-pipeline-model-group \\ --model-package-description \u0026#34;ML pipeline v1 model\u0026#34; \\ --model-approval-status Approved \\ --inference-specification \u0026#39;{\u0026#34;Containers\u0026#34;: [{\u0026#34;Image\u0026#34;: \u0026#34;\u0026lt;IMAGE_URI\u0026gt;\u0026#34;, \u0026#34;ModelDataUrl\u0026#34;: \u0026#34;s3://ml-pipeline-bucket/model/model.tar.gz\u0026#34;}], \u0026#34;SupportedContentTypes\u0026#34;: [\u0026#34;text/csv\u0026#34;], \u0026#34;SupportedResponseMIMETypes\u0026#34;: [\u0026#34;text/csv\u0026#34;]}\u0026#39; 🧹 7. Cập nhật và kiểm soát vòng đời mô hình Khi huấn luyện mô hình mới, bạn chỉ cần tạo một Model Package mới trong cùng một Model Package Group. Điều này giúp theo dõi lịch sử mô hình và dễ dàng rollback nếu mô hình mới không đạt yêu cầu. 🎯 Hoàn thành Bạn đã đăng ký thành công mô hình đã huấn luyện vào SageMaker Model Registry, đồng thời quản lý phiên bản và trạng thái phê duyệt. Đây là bước quan trọng giúp quy trình ML của bạn có tính tổ chức và dễ dàng triển khai mô hình vào production. "
},
{
	"uri": "//localhost:1313/vi/3-create-s3-bucket/3.1-create-an-bucket-to-store-data/",
	"title": "Tạo Bucket S3",
	"tags": [],
	"description": "",
	"content": "Amazon S3 là gì? Amazon S3 (Simple Storage Service) là dịch vụ lưu trữ đối tượng (object storage) của AWS, có khả năng mở rộng gần như vô hạn, độ bền cao và dễ dàng tích hợp với các dịch vụ khác như Lambda, CloudFront, và API Gateway.\nTrong dự án này, S3 sẽ đóng vai trò là nơi lưu trữ toàn bộ dữ liệu tĩnh như:\n🗂️ Frontend web đã build bằng React.js 🖼️ Hình ảnh và nội dung bài viết (media) 📦 File tạm thời hoặc dữ liệu cần cho Lambda xử lý Vì sao cần tạo S3 Bucket? 📁 Lưu trữ tĩnh website: Upload toàn bộ frontend (HTML, CSS, JS) sau khi build để website có thể truy cập qua CloudFront. 🔁 Kết hợp với CloudFront: S3 là nguồn dữ liệu gốc cho CDN giúp tối ưu tốc độ tải trang. 🔐 Tích hợp với Lambda: Cho phép Lambda truy cập/ghi dữ liệu khi cần xử lý. ⚙️ Serverless kiến trúc: Không cần máy chủ để lưu trữ nội dung, tất cả chạy hoàn toàn serverless. 🪣 3.1. Tạo S3 Bucket Truy cập AWS Management Console Mở dịch vụ Amazon S3. Trong menu bên trái, chọn Buckets, sau đó nhấn Create bucket. Trong giao diện Create bucket: Bucket name: đặt tên duy nhất toàn cầu, ví dụ: my-serverless-blog-bucket AWS Region: chọn cùng region với Lambda và DynamoDB (ví dụ: us-east-1) Block Public Access: bỏ chọn nếu bạn muốn bucket public để lưu frontend (sẽ chỉnh sau). Các phần khác giữ mặc định. Nhấn Create bucket 💡 Gợi ý: Bucket name phải duy nhất toàn cầu – nếu tên bạn nhập đã tồn tại, hãy thêm hậu tố như -2025 hoặc tên dự án của bạn.\n📂 3.2. Kiểm tra và cấu hình Bucket Sau khi tạo, bạn sẽ thấy bucket của mình trong danh sách. Nhấn vào tên bucket để mở chi tiết. Vào tab Properties để kiểm tra cấu hình tổng quan. Vào tab Permissions để cấu hình truy cập (quan trọng nếu bạn muốn lưu frontend công khai). ⚠️ Nếu bạn định host website tĩnh từ S3, cần cho phép truy cập công khai.\nHãy chắc chắn bạn hiểu rõ rủi ro bảo mật khi bật public access.\n✅ Hoàn thành 🎉 Bạn đã tạo thành công một S3 Bucket – thành phần lưu trữ trung tâm trong kiến trúc serverless của dự án.\nTrong các bước tiếp theo, chúng ta sẽ:\nUpload frontend đã build vào bucket Kết nối CloudFront để phân phối nội dung toàn cầu Cấu hình Lambda để ghi/đọc dữ liệu nếu cần 📌 Tóm tắt: S3 là nền tảng lưu trữ dữ liệu tĩnh và nội dung cho ứng dụng web. Hãy đảm bảo bucket nằm cùng region với các dịch vụ khác để tránh lỗi quyền truy cập và tối ưu chi phí.\n"
},
{
	"uri": "//localhost:1313/vi/3-create-s3-bucket/",
	"title": "Tạo Bucket S3 để Lưu trữ Dữ liệu",
	"tags": [],
	"description": "",
	"content": "Trong phần này, chúng ta sẽ tạo một Amazon S3 bucket để làm nơi lưu trữ trung tâm cho toàn bộ dữ liệu của dự án Machine Learning Pipeline.\nS3 sẽ đóng vai trò là data lake – nơi chứa dữ liệu đầu vào (raw data), dữ liệu sau tiền xử lý (processed data), kết quả huấn luyện mô hình (model artifacts) cũng như dữ liệu dự đoán (inference results). Đây là điểm khởi đầu quan trọng để pipeline có thể vận hành tự động và liên kết giữa các dịch vụ AWS.\n💡 Gợi ý: Luôn chọn cùng một region cho S3, Lambda và SageMaker để giảm độ trễ và tránh lỗi quyền truy cập.\nNội dung 3.1. Tạo S3 Bucket để lưu trữ dữ liệu 3.2. Cấu trúc tổ chức dữ liệu trong S3 3.3. Tải dữ liệu mẫu lên S3 để test pipeline 📦 Amazon S3 (Simple Storage Service) là dịch vụ lưu trữ đối tượng giúp bạn dễ dàng quản lý dữ liệu lớn, tự động mở rộng quy mô và tích hợp liền mạch với các dịch vụ như Lambda, SageMaker, và API Gateway.\n"
},
{
	"uri": "//localhost:1313/vi/3-create-s3-bucket/3.2-organize-data-structure/",
	"title": "Tổ chức Cấu trúc Dữ liệu",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ học cách tổ chức cấu trúc dữ liệu (thư mục và tệp tin) bên trong Amazon S3 bucket đã tạo ở bước trước. Việc tổ chức dữ liệu hợp lý giúp frontend (React/Vite) dễ dàng được phân phối qua CloudFront và backend truy cập nội dung đúng cách.\n📁 Vì sao cần tổ chức cấu trúc dữ liệu? Một S3 bucket không có khái niệm thư mục thực sự – nó tổ chức dữ liệu bằng key prefix (chuỗi tên tệp). Việc sắp xếp dữ liệu hợp lý sẽ giúp:\nDễ dàng quản lý và cập nhật nội dung frontend. Phân quyền truy cập chi tiết nếu sau này có nhiều nhóm làm việc. Tối ưu cache khi phân phối qua CloudFront. 🧱 Cấu trúc thư mục khuyến nghị Tạo cấu trúc như sau trong bucket S3:\nmy-blog-frontend/ │ ├─ index.html ├─ favicon.ico ├─ /assets/ │ ├─ logo.png │ └─ styles.css ├─ /js/ │ └─ main.js └─ /posts/ └─ sample-post.json 📄 index.html – file gốc của ứng dụng React/Vite. 📁 /assets/ – chứa hình ảnh, CSS. 📁 /js/ – chứa các file JavaScript build ra từ ứng dụng frontend. 📁 /posts/ – (tuỳ chọn) chứa các bài viết mẫu hoặc JSON nội dung tĩnh. 🪄 Thêm dữ liệu mẫu để kiểm tra bucket Truy cập vào Amazon S3 Console. Chọn bucket bạn đã tạo ở bước 3.1. Nhấn Upload. Tải lên file index.html và các thư mục như trên. Sau khi tải lên, bạn sẽ thấy cấu trúc thư mục trong bucket tương tự như hình: Tên thư mục không bắt buộc nhưng nên tuân theo cấu trúc trên để dễ tích hợp với CloudFront và CI/CD sau này. Đảm bảo file index.html nằm ở root của bucket, vì đó là entry point của website. Nếu bạn dùng React Router, bật Static website hosting trong phần “Properties” để S3 có thể xử lý routing đúng cách. ✅ Hoàn thành Bạn đã tổ chức thành công cấu trúc dữ liệu trong S3 bucket và thêm dữ liệu mẫu để chuẩn bị cho bước triển khai frontend.\n"
},
{
	"uri": "//localhost:1313/vi/4-implement-lambda-preprocessing/",
	"title": "Triển khai Hàm Xử lý Trước Lambda",
	"tags": [],
	"description": "",
	"content": "Trong phần này, chúng ta sẽ xây dựng Lambda Preprocessing Function để tự động xử lý dữ liệu thô được tải lên S3. Đây là bước khởi đầu quan trọng trong pipeline machine learning — đảm bảo dữ liệu sạch, chuẩn hóa và sẵn sàng cho quá trình huấn luyện mô hình trên Amazon SageMaker.\n🎯 Mục tiêu Xây dựng Lambda function bằng Python để xử lý dữ liệu CSV từ S3. Tự động kích hoạt Lambda khi có file mới trong thư mục raw/. Ghi kết quả đã xử lý vào thư mục processed/ trong cùng bucket. Đảm bảo dữ liệu sẵn sàng cho bước huấn luyện mô hình SageMaker. 🧠 Tổng quan kiến trúc Dưới đây là cách Lambda Preprocessing Function hoạt động trong toàn bộ pipeline:\n📁 S3 Bucket ├── raw/ ← CSV thô được upload lên ├── processed/ ← CSV đã xử lý, sẵn sàng train Bước 1: Người dùng hoặc hệ thống upload file CSV vào raw/. Bước 2: S3 kích hoạt Lambda qua trigger. Bước 3: Lambda đọc file, làm sạch dữ liệu (loại bỏ dòng lỗi, xử lý giá trị trống…). Bước 4: Lambda ghi file đã xử lý vào processed/. 🛠️ 4.1 – Tạo Lambda Function Truy cập AWS Lambda Console. Nhấn Create function. Cấu hình: Function name: preprocessData Runtime: Python 3.9 Role: Chọn IAM role đã tạo ở bước trước (có quyền S3). 📜 4.2 – Viết mã xử lý dữ liệu Trong tab Code, thay thế nội dung mặc định bằng đoạn mã sau:\nimport boto3 import csv import io import os s3 = boto3.client(\u0026#39;s3\u0026#39;) def lambda_handler(event, context): # Lấy bucket và key của file mới upload bucket = event[\u0026#39;Records\u0026#39;][0][\u0026#39;s3\u0026#39;][\u0026#39;bucket\u0026#39;][\u0026#39;name\u0026#39;] key = event[\u0026#39;Records\u0026#39;][0][\u0026#39;s3\u0026#39;][\u0026#39;object\u0026#39;][\u0026#39;key\u0026#39;] print(f\u0026#34;Processing file: s3://{bucket}/{key}\u0026#34;) # Đọc file CSV từ S3 try: response = s3.get_object(Bucket=bucket, Key=key) raw_bytes = response[\u0026#39;Body\u0026#39;].read() try: content = raw_bytes.decode(\u0026#39;utf-8\u0026#39;) # Thử decode UTF-8 except UnicodeDecodeError: content = raw_bytes.decode(\u0026#39;utf-16\u0026#39;) # Nếu lỗi, thử UTF-16 except Exception as e: print(f\u0026#34;Error reading file from S3: {e}\u0026#34;) raise e reader = csv.reader(io.StringIO(content)) processed_rows = [] for row in reader: # Bỏ qua dòng rỗng hoặc lỗi if all(row): processed_rows.append(row) # Viết file đã xử lý vào folder processed/ output_prefix = os.getenv(\u0026#39;OUTPUT_PREFIX\u0026#39;, \u0026#39;processed/\u0026#39;) output_key = os.path.join(output_prefix, os.path.basename(key)) output_content = io.StringIO() writer = csv.writer(output_content) writer.writerows(processed_rows) # Upload file đã xử lý lên S3 try: s3.put_object( Bucket=bucket, Key=output_key, Body=output_content.getvalue().encode(\u0026#39;utf-8\u0026#39;), ContentType=\u0026#39;text/csv\u0026#39; ) print(f\u0026#34;Processed file saved to s3://{bucket}/{output_key}\u0026#34;) except Exception as e: print(f\u0026#34;Error writing file to S3: {e}\u0026#34;) raise e return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: f\u0026#34;Processed file saved to {output_key}\u0026#34; } ⚙️ 4.3 – Gán Environment Variables Trong tab Configuration → Environment variables, nhấn Edit và thêm:\nKey: OUTPUT_PREFIX Value: processed/ Biến môi trường giúp bạn dễ dàng thay đổi đường dẫn lưu output mà không cần chỉnh sửa mã nguồn.\n📦 4.4 – Đóng gói và Upload Lambda (tùy chọn cục bộ) Nếu phát triển trên máy tính cục bộ:\npip install -r requirements.txt -t . zip -r preprocessData.zip . Sau đó quay lại Lambda Console → tab Code → Upload from → .zip file.\nTạo file requirements.txt với nội dung:\nboto3 🔔 4.5 – Kết nối Lambda với S3 (Trigger) Trong Lambda Console, vào tab Configuration → Triggers.\nNhấn Add trigger.\nChọn:\nTrigger type: S3 Bucket: your-raw-data-bucket Event type: PUT Prefix: raw/ 📸 Ví dụ cấu hình trigger:\nĐảm bảo bucket và Lambda ở cùng region. Nếu không, trigger sẽ không hoạt động.\n🧪 4.6 – Kiểm tra Preprocessing Function Upload một file CSV mẫu vào thư mục raw/:\naws s3 cp data.csv s3://ml-pipeline-bucket/raw/data.csv Lambda sẽ tự động chạy và tạo file đã xử lý trong processed/.\n📊 Ví dụ kết quả:\nInput: s3://ml-pipeline-bucket/raw/data.csv Output: s3://ml-pipeline-bucket/processed/data.csv ✅ Hoàn thành 🎉 Bạn đã triển khai thành công Lambda Preprocessing Function – bước khởi đầu trong pipeline machine learning.\n"
},
{
	"uri": "//localhost:1313/vi/5-train-model-with-sagemaker/5.4-validate-training-results/",
	"title": "Xác thực Kết quả Huấn luyện Mô hình",
	"tags": [],
	"description": "",
	"content": "Trong phần này, chúng ta sẽ học cách xác thực kết quả huấn luyện để đảm bảo mô hình đã được huấn luyện thành công và đạt chất lượng trước khi triển khai vào production. Đây là một bước rất quan trọng trong quy trình ML pipeline vì nó giúp bạn đánh giá chất lượng mô hình, kiểm tra output và quyết định có nên triển khai hay cần điều chỉnh lại dữ liệu/siêu tham số.\n🎯 Mục tiêu Kiểm tra trạng thái job huấn luyện trong SageMaker. Phân tích log và output của quá trình training. Đánh giá metrics (độ chính xác, F1, AUC…) của mô hình. Xác thực file mô hình đầu ra trước khi đưa vào Model Registry hoặc deploy. 📊 1. Kiểm tra trạng thái Training Job Truy cập vào AWS Management Console → Amazon SageMaker → Training jobs để xem danh sách job huấn luyện đã tạo ở bước 5.2 – Tạo Training Job.\nCột Status sẽ hiển thị trạng thái: ✅ Completed – Hoàn tất thành công. ❌ Failed – Huấn luyện thất bại (kiểm tra log). 🕐 InProgress – Đang huấn luyện. Nếu trạng thái là Failed, hãy kiểm tra log CloudWatch để xác định nguyên nhân (ví dụ: lỗi quyền S3, lỗi code training script, hoặc thiếu dữ liệu).\n📁 2. Kiểm tra Output Model trong S3 Sau khi huấn luyện thành công, SageMaker sẽ lưu mô hình vào S3 theo đường dẫn bạn đã chỉ định: s3://ml-pipeline-bucket/model/model.tar.gz\nmodel.tar.gz chứa mô hình đã được serialize (ví dụ: pickle, joblib hoặc định dạng framework như TensorFlow SavedModel). Bạn có thể tải file này về máy và kiểm tra cấu trúc để đảm bảo nội dung hợp lệ. 📜 3. Phân tích log trong CloudWatch Vào CloudWatch Logs → Log groups → tìm nhóm log tương ứng với training job. Xem log output từ script huấn luyện – bạn sẽ thấy thông tin như: [INFO] Training accuracy: 0.912 [INFO] Validation accuracy: 0.905 [INFO] Model saved to /opt/ml/model/ 📌 Nếu bạn ghi metrics ra stdout hoặc lưu vào /opt/ml/output/metrics.json, SageMaker sẽ tự động thu thập để hiển thị trong giao diện.\n📈 4. Đánh giá metrics huấn luyện Metrics là thước đo chính để quyết định mô hình có thể đưa vào production hay không.\nMột số metrics phổ biến:\nMetric Ý nghĩa Accuracy Tỷ lệ dự đoán đúng trên tổng số mẫu. Precision Độ chính xác khi mô hình dự đoán Positive. Recall Khả năng phát hiện toàn bộ Positive cases. F1-Score Trung bình điều hòa giữa Precision và Recall. AUC-ROC Khả năng phân biệt giữa các lớp. Bạn nên đặt ngưỡng tối thiểu cho các metrics này (ví dụ: Accuracy \u0026gt; 0.90) để tự động phê duyệt hoặc từ chối mô hình trước khi đăng ký.\n🔬 5. Xác thực tính đúng đắn của mô hình Kiểm tra mô hình có thể load và inference cục bộ không: import joblib model = joblib.load(\u0026#34;model.tar.gz\u0026#34;) print(model.predict([[5.1, 3.5, 1.4, 0.2]])) Nếu dùng TensorFlow/PyTorch, kiểm tra bằng hàm load_model() hoặc torch.load(). Nếu mô hình không thể load, có thể training script đã không lưu mô hình đúng định dạng. ✅ 6. Đánh giá và Quyết định Dựa vào kết quả validation, bạn có thể đưa ra các quyết định sau:\n✅ Nếu mô hình đạt yêu cầu → Tiếp tục đăng ký vào Model Registry hoặc triển khai. ⚠️ Nếu mô hình chưa đủ tốt → Điều chỉnh dữ liệu, siêu tham số hoặc mô hình → huấn luyện lại. 📊 Ví dụ về kết quả đánh giá: Metric Giá trị Ngưỡng yêu cầu Kết luận Accuracy 0.912 \u0026gt;0.90 ✅ Passed Precision 0.908 \u0026gt;0.85 ✅ Passed Recall 0.901 \u0026gt;0.85 ✅ Passed F1-Score 0.905 \u0026gt;0.85 ✅ Passed 🎉 Hoàn thành Bạn đã xác thực thành công kết quả huấn luyện mô hình trong SageMaker Đây là bước quan trọng đảm bảo chất lượng trước khi mô hình được đăng ký và triển khai. "
},
{
	"uri": "//localhost:1313/vi/5-train-model-with-sagemaker/",
	"title": "Đào tạo và Đăng ký Mô hình với Amazon SageMaker",
	"tags": [],
	"description": "",
	"content": "Trong phần này, chúng ta sẽ huấn luyện mô hình machine learning với Amazon SageMaker bằng dữ liệu đã được tiền xử lý từ Lambda và lưu trên S3. Đây là bước quan trọng để tạo ra mô hình sẵn sàng phục vụ inference thông qua API sau này.\n🎯 Mục tiêu Tìm hiểu cách tạo SageMaker Training Job từ dữ liệu đã xử lý. Cấu hình các tham số huấn luyện và lựa chọn thuật toán. Đăng ký mô hình (Model Registry) để triển khai sau này. Quản lý version mô hình và theo dõi quá trình huấn luyện. 📚 Nội dung 5.1 Chuẩn bị dữ liệu đầu vào cho SageMaker 5.2 Tạo SageMaker Training Job 5.3 Đăng ký mô hình và quản lý phiên bản 5.4 Kiểm tra kết quả huấn luyện 🧠 Tổng quan kiến trúc Lambda tạo dữ liệu đã xử lý và lưu vào thư mục processed/ trên S3. SageMaker đọc dữ liệu từ S3, huấn luyện mô hình theo thuật toán bạn chọn. Kết quả mô hình được lưu trong model/ và có thể đăng ký vào Model Registry. Mô hình đã đăng ký sẽ dùng để triển khai inference ở bước tiếp theo. 📦 Yêu cầu trước khi bắt đầu Đã hoàn thành Lambda Preprocessing Function (Chương 4). Có dữ liệu đã xử lý nằm trong thư mục processed/ của bucket S3. IAM Role của SageMaker có quyền truy cập S3, CloudWatch, và SageMaker. ✅ Sau khi hoàn thành chương này, bạn sẽ có một mô hình ML được huấn luyện và đăng ký\n"
},
{
	"uri": "//localhost:1313/vi/3-create-s3-bucket/3.3-upload-sample-data/",
	"title": "Tải lên dữ liệu mẫu",
	"tags": [],
	"description": "",
	"content": "Trong phần này, chúng ta sẽ tải lên dữ liệu mẫu (frontend build) vào Amazon S3 bucket để kiểm tra khả năng truy cập website tĩnh trước khi kết nối với API Gateway và Lambda.\n📦 Vì sao cần upload dữ liệu mẫu? Việc tải dữ liệu mẫu vào S3 giúp bạn:\n✅ Xác minh bucket đã hoạt động chính xác và website có thể được phân phối. ✅ Kiểm tra khả năng truy cập của frontend React/Vite qua trình duyệt. ✅ Đảm bảo cấu trúc dữ liệu đúng trước khi tích hợp với backend. Bước 1 – Build ứng dụng frontend Nếu bạn dùng React + Vite, trong thư mục frontend chạy:\nnpm install npm run build Lệnh này sẽ tạo thư mục dist/ (hoặc build/) chứa file tĩnh sẵn sàng để upload lên S3.\nCấu trúc thư mục sau khi build có thể như sau: dist/ │ ├─ index.html ├─ favicon.ico ├─ assets/ │ ├─ main.js │ └─ style.css └─ logo.png Bước 2 - Upload frontend build lên S3 Truy cập Amazon S3 Console Chọn bucket mà bạn đã tạo ở bước 3.1 Create S3 Bucket Nhấn nút Upload Chọn toàn bộ nội dung trong thư mục dist/ (hoặc build/) Nhấn Upload để hoàn tất quá trình tải lên Ví dụ minh họa quá trình upload: Bước 3 – Kích hoạt Static Website Hosting (nếu chưa bật) Trong tab Properties của bucket Cuộn xuống phần Static website hosting Chọn Enable Chỉ định: Index document: index.html Error document: index.html (nếu dùng React Router) File index.html phải nằm ở root của bucket, không nằm trong thư mục con. Nếu website có routing (SPA), đặt cả Error document = index.html.\nBước 4 – Kiểm tra truy cập website Sao chép Static website endpoint URL từ phần cấu hình bucket. Dán URL vào trình duyệt để kiểm tra kết quả. Ví dụ: http://my-blog-frontend.s3-website-ap-southeast-1.amazonaws.com Kết quả khi truy cập thành công: Lưu ý quan trọng Kiểm tra lại permissions của bucket nếu bạn không truy cập được website. Đảm bảo file index.html đã được upload đúng vị trí. Nếu muốn dùng CloudFront sau này, không cần bật \u0026ldquo;Public access\u0026rdquo; cho bucket – CloudFront sẽ truy cập thay bạn.\n✅ Hoàn thành Bạn đã tải thành công frontend build mẫu lên S3 bucket và xác minh khả năng truy cập website tĩnh.\n"
},
{
	"uri": "//localhost:1313/vi/6-deploy-sagemaker-endpoint/",
	"title": "Triển khai Endpoint của SageMaker cho Inference",
	"tags": [],
	"description": "",
	"content": "\nTrong phần này, chúng ta sẽ triển khai mô hình đã train từ bước 5 lên Amazon SageMaker Endpoint, cho phép gọi inference thông qua API hoặc Lambda function. Đây là bước quan trọng để biến mô hình ML của bạn thành một dịch vụ có thể sử dụng trong thực tế.\n🎯 Mục tiêu Tạo endpoint từ model đã train và register ở bước trước. Kiểm tra endpoint bằng dữ liệu mẫu. Chuẩn bị endpoint để tích hợp với Lambda ở bước tiếp theo. 🧠 6.1 – Tạo SageMaker Model từ Artifact Sau khi train và đăng ký model (bước 5), chúng ta sẽ tạo một SageMaker Model dựa trên output đó.\nTruy cập SageMaker Console → Inference → Models\nNhấn Create model\nCấu hình:\nModel name: ml-blog-model Execution role: Chọn IAM role đã tạo ở bước trước (SageMakerExecutionRole) Container definition: Image: 382416733822.dkr.ecr.ap-southeast-1.amazonaws.com/xgboost:latest (hoặc image bạn đã dùng khi train) Model artifact location: s3://ml-pipeline-bucket/model/xgboost-model.tar.gz Nhấn Create model để hoàn tất. 📌 Lưu ý: Container image và đường dẫn artifact phải trùng khớp với job train đã tạo trước đó.\n⚙️ 6.2 – Tạo Endpoint Configuration Điều hướng đến Inference → Endpoint configurations\nChọn Create endpoint configuration\nCấu hình:\nName: ml-blog-endpoint-config Model name: ml-blog-model Instance type: ml.m5.large (hoặc ml.t2.medium nếu muốn tiết kiệm chi phí) Initial instance count: 1 Nhấn Create endpoint configuration 🌐 6.3 – Triển khai SageMaker Endpoint Điều hướng đến Inference → Endpoints\nChọn Create endpoint\nNhập:\nEndpoint name: ml-blog-endpoint Endpoint configuration: Chọn ml-blog-endpoint-config Nhấn Create endpoint. Quá trình tạo sẽ mất vài phút ⏳.\n📸 Ví dụ giao diện triển khai:\nĐảm bảo IAM Role có quyền truy cập S3 và SageMaker (AmazonSageMakerFullAccess, AmazonS3ReadOnlyAccess). Endpoint phải ở trạng thái InService trước khi sử dụng inference. 🧪 6.4 – Kiểm tra Endpoint bằng boto3 (Python) Sau khi endpoint ở trạng thái InService, hãy kiểm tra inference bằng đoạn mã Python sau:\nimport boto3 import json runtime = boto3.client(\u0026#39;sagemaker-runtime\u0026#39;) payload = { \u0026#34;features\u0026#34;: [0.56, 0.32, 0.78, 0.12] # ví dụ dữ liệu input } response = runtime.invoke_endpoint( EndpointName=\u0026#39;ml-blog-endpoint\u0026#39;, ContentType=\u0026#39;application/json\u0026#39;, Body=json.dumps(payload) ) result = json.loads(response[\u0026#39;Body\u0026#39;].read().decode()) print(\u0026#34;📊 Kết quả dự đoán:\u0026#34;, result) ✅ Kết quả sẽ trả về giá trị dự đoán (ví dụ: 1 hoặc 0 cho mô hình phân loại). .\n📊 6.5 – Giám sát Endpoint với CloudWatch Vào CloudWatch → Logs để xem log inference. Theo dõi metric như:\nInvocations Invocation4XXErrors ModelLatency Điều này giúp đánh giá hiệu năng mô hình trong môi trường production. 📌 Bạn có thể bật Auto Scaling cho endpoint bằng cách dùng Application Auto Scaling để tự động tăng/giảm số instance theo lưu lượng inference.\n✅ Hoàn thành Bạn đã triển khai thành công một SageMaker Endpoint từ mô hình đã train.\n"
},
{
	"uri": "//localhost:1313/vi/7-build-lambda-inference-and-api/",
	"title": "Xây dựng Lambda Function và REST API cho Inference",
	"tags": [],
	"description": "",
	"content": "\nTrong phần này, chúng ta sẽ triển khai một Lambda function để gọi mô hình đã triển khai trên SageMaker Endpoint (bước 6) và tạo một REST API Gateway để client có thể gửi yêu cầu inference. Đây là mắt xích quan trọng giúp biến mô hình ML thành một dịch vụ dự đoán hoàn chỉnh.\n🎯 Mục tiêu Tạo Lambda function gọi SageMaker Endpoint để xử lý inference. Kết nối Lambda với API Gateway để tạo REST API. Kiểm tra inference từ Postman hoặc trình duyệt. 🧠 7.1 – Tạo Lambda Function để gọi SageMaker Endpoint Truy cập AWS Management Console → Lambda → Create function\nCấu hình:\nFunction name: invoke-ml-endpoint Runtime: Python 3.9 Execution role: Chọn role có quyền gọi SageMaker (hoặc tạo role mới với quyền AmazonSageMakerFullAccess và AWSLambdaBasicExecutionRole) Nhấn Create function ✏️ 7.2 – Viết mã Lambda để gọi Endpoint Thay nội dung mặc định trong tab Code bằng đoạn mã sau:\nimport json import boto3 import os runtime = boto3.client(\u0026#39;sagemaker-runtime\u0026#39;) ENDPOINT_NAME = os.environ.get(\u0026#39;ENDPOINT_NAME\u0026#39;, \u0026#39;ml-blog-endpoint\u0026#39;) def lambda_handler(event, context): try: body = json.loads(event[\u0026#39;body\u0026#39;]) features = body.get(\u0026#39;features\u0026#39;) if features is None: return { \u0026#34;statusCode\u0026#34;: 400, \u0026#34;body\u0026#34;: json.dumps({\u0026#34;error\u0026#34;: \u0026#34;Missing \u0026#39;features\u0026#39; in request body\u0026#34;}) } response = runtime.invoke_endpoint( EndpointName=ENDPOINT_NAME, ContentType=\u0026#39;application/json\u0026#39;, Body=json.dumps({\u0026#34;features\u0026#34;: features}) ) result = json.loads(response[\u0026#39;Body\u0026#39;].read().decode()) return { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;headers\u0026#34;: {\u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;}, \u0026#34;body\u0026#34;: json.dumps({\u0026#34;prediction\u0026#34;: result}) } except Exception as e: return { \u0026#34;statusCode\u0026#34;: 500, \u0026#34;body\u0026#34;: json.dumps({\u0026#34;error\u0026#34;: str(e)}) } 📌 Giải thích:\nENDPOINT_NAME: tên endpoint đã triển khai ở bước 6. Lambda nhận dữ liệu JSON từ client (features), gọi SageMaker endpoint, và trả kết quả dự đoán. Trong phần Configuration → Environment variables, thêm biến:\nKey: ENDPOINT_NAME Value: ml-blog-endpoint Nhấn Deploy để lưu function.\n🌐 7.3 – Tạo REST API Gateway kết nối Lambda Truy cập API Gateway → Create API\nChọn REST API → Build API name: InferenceAPI Endpoint Type: Regional Tạo resource /predict:\nTrong Resources, chọn Actions → Create Resource Resource name: predict Resource path: /predict Bật Enable API Gateway CORS → Create Resource Thêm phương thức POST:\nChọn /predict → Actions → Create Method → POST Integration type: Lambda Function Lambda Function: invoke-ml-endpoint Nhấn Save và xác nhận quyền. 🔄 7.4 – Bật CORS và Triển khai API Trong Resources, chọn Actions → Enable CORS Giữ cấu hình mặc định và nhấn Enable CORS and replace existing CORS headers Triển khai API: Actions → Deploy API Deployment stage: [New Stage] → đặt tên prod Nhấn Deploy 📌 Lưu lại Invoke URL ví dụ:\nhttps://abc123xyz.execute-api.ap-southeast-1.amazonaws.com/prod/predict 🧪 7.5 – Kiểm tra API Inference Bạn có thể dùng Postman hoặc lệnh curl để kiểm tra:\ncurl -X POST \\ https://abc123xyz.execute-api.ap-southeast-1.amazonaws.com/prod/predict \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;features\u0026#34;: [0.45, 0.12, 0.88, 0.33] }\u0026#39; ✅ Phản hồi mẫu: { \u0026#34;prediction\u0026#34;: 1 } 📊 7.6 – Ghi log và giám sát Kiểm tra log Lambda trong CloudWatch Logs → giúp debug nếu xảy ra lỗi. Theo dõi metric như Invocations, 4XXError, Latency để đảm bảo API hoạt động ổn định. 💡 Bạn có thể thêm xác thực API bằng API Keys, Cognito User Pools hoặc IAM Auth nếu triển khai trong môi trường production.\n✅ Hoàn thành 🎉 Bạn đã xây dựng thành công một Lambda function để gọi SageMaker Endpoint, tạo REST API Gateway, và kiểm tra inference thành công.\n"
},
{
	"uri": "//localhost:1313/vi/8-integrate-dynamodb-and-cloudwatch/8.1-create-dynamodb-table/",
	"title": "Tạo bảng DynamoDB để lưu metadata inference",
	"tags": [],
	"description": "",
	"content": "Amazon DynamoDB là một dịch vụ cơ sở dữ liệu NoSQL hoàn toàn managed, hiệu năng cao và tự động mở rộng. Trong dự án này, DynamoDB sẽ được sử dụng để lưu trữ metadata của các yêu cầu inference từ mô hình, bao gồm đầu vào, đầu ra, thời gian xử lý và thông tin mô hình.\nViệc này giúp chúng ta dễ dàng phân tích, giám sát và truy xuất lịch sử inference khi cần thiết.\nDynamoDB trong dự án Machine Learning Pipeline Trong phần này, chúng ta sẽ:\nTạo một bảng DynamoDB để lưu trữ metadata mỗi lần inference. Xác định Primary key và các trường quan trọng. Cấu hình quyền truy cập để Lambda có thể ghi dữ liệu vào bảng. Kiểm tra bảng và xác minh dữ liệu được ghi thành công. 🎯 Lợi ích khi sử dụng DynamoDB: Serverless \u0026amp; Tự động mở rộng: Không cần quản lý máy chủ hay phân vùng dữ liệu. Hiệu năng cao: Đáp ứng hàng triệu yêu cầu mỗi giây. Dễ dàng tích hợp: Làm việc trực tiếp với Lambda và các dịch vụ khác của AWS. Theo dõi lịch sử inference: Lưu lại chi tiết đầu vào, đầu ra và thời gian inference. 🛠️ Tạo bảng DynamoDB Truy cập AWS Management Console Trong thanh tìm kiếm, nhập DynamoDB và chọn dịch vụ này. Tạo bảng mới Chọn Create table.\nTable name: Nhập tên bảng, ví dụ: InferenceMetadata.\nPartition key: Nhập requestId (kiểu String).\nKhông cần thêm Sort key (tùy chọn).\nGiữ các cài đặt còn lại mặc định.\nNhấn Create table.\nCấu trúc dữ liệu gợi ý Mỗi bản ghi trong bảng có thể chứa các trường sau:\nTrường Kiểu dữ liệu Mô tả requestId String ID duy nhất cho mỗi yêu cầu inference timestamp String Thời gian thực hiện inference modelName String Tên mô hình sử dụng inputData String Dữ liệu đầu vào prediction String Kết quả mô hình trả về latencyMs Number Độ trễ (ms) của quá trình inference Cấp quyền truy cập cho Lambda\nMở IAM Console, chọn role của Lambda inference (ví dụ: lambda-inference-role). Thêm quyền truy cập DynamoDB bằng cách attach policy sau: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;dynamodb:DescribeTable\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:\u0026lt;region\u0026gt;:\u0026lt;account-id\u0026gt;:table/InferenceMetadata\u0026#34; } ] } Đảm bảo Partition key là duy nhất để tránh ghi đè dữ liệu. Ghi lại tên bảng để sử dụng trong bước cấu hình Lambda (8.2). Role Lambda phải có quyền PutItem để ghi dữ liệu vào bảng.\nKiểm tra bảng\nSau khi Lambda ghi dữ liệu inference, vào tab Explore table items của bảng InferenceMetadata. Bạn sẽ thấy các bản ghi chứa đầy đủ thông tin mỗi lần inference. ✅ Hoàn thành Bạn đã tạo bảng DynamoDB để lưu metadata inference. Đây là nền tảng để Lambda có thể ghi dữ liệu sau mỗi lần dự đoán, phục vụ mục tiêu phân tích và giám sát ở bước tiếp theo. "
},
{
	"uri": "//localhost:1313/vi/8-integrate-dynamodb-and-cloudwatch/",
	"title": "Tích hợp DynamoDB và CloudWatch",
	"tags": [],
	"description": "",
	"content": "DynamoDB \u0026amp; CloudWatch trong ML Pipeline Trong bước cuối cùng của pipeline, chúng ta sẽ tích hợp Amazon DynamoDB để lưu trữ metadata của các yêu cầu inference và thông tin mô hình, đồng thời sử dụng Amazon CloudWatch để theo dõi logs, đo lường hiệu năng và tạo cảnh báo khi có sự cố.\nĐây là bước quan trọng để đảm bảo pipeline có thể vận hành bền vững trong môi trường thực tế.\n🗃️ DynamoDB – Lưu trữ metadata inference Amazon DynamoDB là cơ sở dữ liệu NoSQL serverless, tự động mở rộng, hiệu năng cao. Trong dự án này, DynamoDB sẽ được dùng để:\nLưu kết quả inference từ Lambda (đầu vào, đầu ra, thời gian). Lưu thông tin mô hình như version, endpoint name. Phục vụ việc giám sát và phân tích hiệu suất sau này. 📊 CloudWatch – Giám sát và phân tích pipeline Amazon CloudWatch là dịch vụ giám sát trung tâm trên AWS.\nNó sẽ giúp bạn:\nTheo dõi logs từ Lambda và SageMaker Endpoint. Tạo metric filter để phân tích số lượng inference, lỗi, độ trễ. Cấu hình alarm khi pipeline có sự cố. 📚 Nội dung 8.1 Tạo bảng DynamoDB để lưu metadata inference 8.2 Cập nhật Lambda để ghi dữ liệu vào DynamoDB 8.3 Giám sát và cảnh báo với CloudWatch 📌 Tổng kết\n✅ Bạn sẽ học cách tạo và quản lý bảng DynamoDB để lưu kết quả inference. ✅ Lambda sẽ được mở rộng để ghi dữ liệu mỗi lần dự đoán. ✅ CloudWatch sẽ giúp bạn giám sát logs, phân tích hiệu suất và tạo cảnh báo. 🎯 Kết quả sau chương này:\nMột pipeline ML hoàn chỉnh có khả năng lưu trữ lịch sử inference, giám sát tự động, và cảnh báo sớm khi có sự cố. Sẵn sàng vận hành ở môi trường production với khả năng mở rộng và bảo trì dễ dàng. "
},
{
	"uri": "//localhost:1313/vi/8-integrate-dynamodb-and-cloudwatch/8.2-update-lambda-to-write-dynamodb/",
	"title": "Cập nhật Lambda để ghi dữ liệu vào DynamoDB",
	"tags": [],
	"description": "",
	"content": "\nTrong phần này, chúng ta sẽ:\nCập nhật hàm Lambda inference để ghi metadata mỗi lần gọi mô hình vào DynamoDB. Kiểm tra dữ liệu được ghi thành công. Xác minh quá trình inference được theo dõi đầy đủ. 🎯 Mục tiêu của bước này: Lưu trữ lịch sử inference: Ghi lại dữ liệu đầu vào, kết quả, thời gian xử lý và thông tin mô hình. Phân tích \u0026amp; Debug dễ dàng: Dữ liệu được lưu giúp theo dõi hành vi mô hình theo thời gian. Tích hợp với giám sát: Chuẩn bị cho bước kết nối với CloudWatch để theo dõi pipeline. 🛠️ Cập nhật Lambda để ghi dữ liệu vào DynamoDB Mở Lambda Function Inference Truy cập AWS Lambda trong Management Console. Chọn hàm Lambda bạn đã tạo để gọi SageMaker Endpoint (ví dụ: ml-inference-lambda). Cập nhật mã nguồn Lambda Thay nội dung file lambda_function.py bằng mã dưới đây để ghi metadata vào bảng InferenceMetadata sau mỗi lần inference:\nimport json import boto3 import os import time import uuid from datetime import datetime sagemaker = boto3.client(\u0026#39;sagemaker-runtime\u0026#39;) dynamodb = boto3.client(\u0026#39;dynamodb\u0026#39;) ENDPOINT_NAME = os.environ[\u0026#39;ENDPOINT_NAME\u0026#39;] TABLE_NAME = os.environ[\u0026#39;DYNAMODB_TABLE\u0026#39;] def lambda_handler(event, context): # Parse input từ API Gateway body = json.loads(event[\u0026#39;body\u0026#39;]) input_data = body[\u0026#39;input\u0026#39;] # Gọi SageMaker endpoint start_time = time.time() response = sagemaker.invoke_endpoint( EndpointName=ENDPOINT_NAME, ContentType=\u0026#39;application/json\u0026#39;, Body=json.dumps(input_data) ) prediction = json.loads(response[\u0026#39;Body\u0026#39;].read()) latency_ms = int((time.time() - start_time) * 1000) # Ghi metadata vào DynamoDB request_id = str(uuid.uuid4()) timestamp = datetime.utcnow().isoformat() dynamodb.put_item( TableName=TABLE_NAME, Item={ \u0026#39;requestId\u0026#39;: {\u0026#39;S\u0026#39;: request_id}, \u0026#39;timestamp\u0026#39;: {\u0026#39;S\u0026#39;: timestamp}, \u0026#39;modelName\u0026#39;: {\u0026#39;S\u0026#39;: ENDPOINT_NAME}, \u0026#39;inputData\u0026#39;: {\u0026#39;S\u0026#39;: json.dumps(input_data)}, \u0026#39;prediction\u0026#39;: {\u0026#39;S\u0026#39;: json.dumps(prediction)}, \u0026#39;latencyMs\u0026#39;: {\u0026#39;N\u0026#39;: str(latency_ms)} } ) # Trả về kết quả inference return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;requestId\u0026#39;: request_id, \u0026#39;prediction\u0026#39;: prediction, \u0026#39;latencyMs\u0026#39;: latency_ms }) } ✅ Trong đó: ENDPOINT_NAME: tên SageMaker Endpoint đã triển khai. TABLE_NAME: tên bảng DynamoDB đã tạo ở 8.1. latencyMs: thời gian inference, tính bằng mili-giây. Thêm biến môi trường cho Lambda Trong trang cấu hình của Lambda → Configuration → Environment variables → Edit. Thêm các biến: ENDPOINT_NAME = tên SageMaker endpoint. DYNAMODB_TABLE = InferenceMetadata. Kiểm tra quyền truy cập IAM Đảm bảo role Lambda có quyền ghi dữ liệu vào DynamoDB như sau: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;dynamodb:DescribeTable\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:\u0026lt;region\u0026gt;:\u0026lt;account-id\u0026gt;:table/InferenceMetadata\u0026#34; } ] } Triển khai và kiểm tra Lambda Nhấn Deploy để lưu thay đổi. Sử dụng Test trong Lambda Console hoặc gửi yêu cầu POST tới API Gateway như sau: curl -X POST \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;input\u0026#34;: {\u0026#34;text\u0026#34;: \u0026#34;Hello AI!\u0026#34;}}\u0026#39; \\ https://\u0026lt;api-id\u0026gt;.execute-api.\u0026lt;region\u0026gt;.amazonaws.com/prod/inference Kiểm tra phản hồi chứa requestId, prediction, và latencyMs. Xác minh dữ liệu trong DynamoDB Mở bảng InferenceMetadata trong DynamoDB Console. Chọn Explore table items để xem dữ liệu được ghi. Bạn sẽ thấy các bản ghi như sau: requestId timestamp modelName inputData prediction latencyMs 6c1a4\u0026hellip; 2025-10-01T10:20:30Z ml-endpoint {\u0026ldquo;text\u0026rdquo;: \u0026ldquo;Hello AI!\u0026rdquo;} {\u0026ldquo;result\u0026rdquo;: \u0026ldquo;positive\u0026rdquo;} 134 Nếu dữ liệu không được ghi, kiểm tra quyền IAM của Lambda. Xác minh tên bảng DynamoDB và biến môi trường chính xác. Xem log chi tiết trong CloudWatch Logs để debug lỗi.\n✅ Hoàn thành Bạn đã cập nhật Lambda để tự động ghi metadata mỗi lần inference vào DynamoDB. Đây là bước quan trọng để kết nối pipeline inference với hệ thống lưu trữ và giám sát. "
},
{
	"uri": "//localhost:1313/vi/9-clean-up-resources/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Sau khi hoàn thành toàn bộ workshop \u0026ldquo;Building an End-to-End Machine Learning Pipeline on AWS\u0026rdquo;, bước cuối cùng là dọn dẹp tất cả tài nguyên AWS mà bạn đã tạo trong quá trình triển khai.\nĐiều này cực kỳ quan trọng để tránh phát sinh chi phí ngoài Free Tier, đảm bảo an toàn bảo mật và giữ cho tài khoản AWS luôn sạch sẽ cho các dự án tiếp theo.\n🎯 Mục tiêu của bước này 💸 Tiết kiệm chi phí: Ngăn chặn chi phí phát sinh từ các dịch vụ không còn sử dụng. 🔐 Bảo mật: Loại bỏ quyền IAM, API và tài nguyên không cần thiết để giảm thiểu rủi ro bảo mật. 🧰 Gọn gàng và dễ quản lý: Giúp tài khoản AWS sạch sẽ và sẵn sàng cho các workshop hoặc dự án mới. 🗑️ Các tài nguyên cần xóa Dưới đây là danh sách tài nguyên đã được sử dụng xuyên suốt dự án mà bạn cần xóa:\nAmazon CloudFront – CDN phân phối ứng dụng và nội dung. Amazon S3 – Lưu trữ dữ liệu và model. Amazon API Gateway – REST API kết nối Lambda và endpoint inference. AWS Lambda – Hàm xử lý dữ liệu, tiền xử lý và suy luận. Amazon DynamoDB – Bảng lưu metadata và kết quả inference. AWS IAM – Vai trò và chính sách cấp quyền cho Lambda và SageMaker. 🧼 Hướng dẫn dọn dẹp chi tiết 1. 🧭 Xóa phân phối CloudFront Truy cập CloudFront từ AWS Management Console. Chọn phân phối bạn đã tạo (ví dụ: d1234567890abcdef.cloudfront.net). Nhấp Disable (Vô hiệu hóa) và đợi trạng thái chuyển sang Disabled. Nhấp Delete (Xóa) để xóa hoàn toàn phân phối. 2. 📦 Xóa bucket Amazon S3 Vào S3 từ bảng điều khiển AWS. Chọn bucket đã tạo (ví dụ: ml-workshop-data-\u0026lt;account-id\u0026gt;). Nhấp Empty, nhập permanently delete để xác nhận, rồi chọn Empty. Khi bucket trống, nhấp Delete bucket, nhập tên bucket để xác nhận xóa. 3. 🌐 Xóa API Gateway Vào API Gateway. Chọn API bạn đã triển khai (ví dụ: InferenceAPI). Nhấp Actions → Delete, nhập tên API để xác nhận và hoàn tất xóa. 4. 🧠 Xóa các hàm AWS Lambda Truy cập Lambda từ bảng điều khiển. Xóa tất cả các hàm bạn đã tạo, ví dụ: preprocessing-function inference-function Nhấp Actions → Delete, xác nhận xóa từng hàm. 5. 📊 Xóa bảng DynamoDB Vào DynamoDB → Tables. Chọn bảng mà bạn đã tạo (ví dụ: InferenceMetadata). Nhấp Actions → Delete table, nhập tên bảng để xác nhận. 6. 🔐 Xóa các tài nguyên IAM Vào IAM trong bảng điều khiển. Trong Policies, chọn chính sách đã tạo (ví dụ: lambda-inference-policy) → Delete. Trong Roles, chọn vai trò liên quan (ví dụ: lambda-inference-role) → Delete. ⚠️ Lưu ý quan trọng:\nĐảm bảo rằng bucket S3 đã trống trước khi xóa. Kiểm tra kỹ các tài nguyên trước khi xóa để tránh xóa nhầm tài nguyên từ dự án khác. Nếu gặp lỗi khi xóa (ví dụ: tài nguyên vẫn đang được tham chiếu), hãy kiểm tra các phụ thuộc như quyền IAM, endpoint API Gateway, hoặc phân phối CloudFront. ✅ Kết quả sau khi dọn dẹp Toàn bộ tài nguyên của dự án đã được xóa. Tài khoản AWS của bạn không còn tài nguyên nào phát sinh chi phí. Bạn có thể bắt đầu các workshop hoặc dự án mới mà không bị xung đột tài nguyên cũ. "
},
{
	"uri": "//localhost:1313/vi/8-integrate-dynamodb-and-cloudwatch/8.3-monitor-with-cloudwatch/",
	"title": "Giám sát với Amazon CloudWatch",
	"tags": [],
	"description": "",
	"content": "\nAmazon CloudWatch là dịch vụ giám sát và quan sát hệ thống trên AWS. Trong dự án này, CloudWatch giúp theo dõi toàn bộ pipeline inference — từ Lambda, SageMaker Endpoint, đến DynamoDB — nhằm đảm bảo hiệu suất, phát hiện lỗi sớm và tối ưu chi phí.\n🎯 Mục tiêu phần này Thu thập và giám sát log từ Lambda và SageMaker. Tạo metric tùy chỉnh để theo dõi số lượng inference, độ trễ và lỗi. Thiết lập cảnh báo (Alarm) khi hiệu suất mô hình hoặc API gặp vấn đề. 1. Kiểm tra log từ Lambda và SageMaker 📜 Log Lambda Truy cập Amazon CloudWatch → Logs → Log groups. Tìm log group tương ứng với Lambda (ví dụ: /aws/lambda/ml-inference-lambda). Kiểm tra chi tiết từng lần gọi inference, bao gồm: Thời gian gọi endpoint. Dữ liệu đầu vào/đầu ra. Thời gian inference (latencyMs). Lỗi (nếu có). 📜 Log SageMaker Endpoint Truy cập Amazon CloudWatch → Logs → Log groups. Tìm log group có tiền tố /aws/sagemaker/Endpoints/ và chọn endpoint tương ứng. Xem log để biết thông tin: Mô hình được gọi bao nhiêu lần. Thời gian phản hồi của container mô hình. Lỗi trong quá trình xử lý inference. Kết hợp log của Lambda và SageMaker để chẩn đoán lỗi nhanh hơn khi inference thất bại.\n2. Tạo Custom Metrics từ Lambda Để giám sát chi tiết hơn (ví dụ: số inference mỗi phút, độ trễ trung bình), bạn có thể gửi Custom Metrics từ Lambda lên CloudWatch.\nCập nhật hàm Lambda như sau:\nimport boto3 import time import os cloudwatch = boto3.client(\u0026#39;cloudwatch\u0026#39;) def publish_metrics(latency_ms, success=True): cloudwatch.put_metric_data( Namespace=\u0026#39;InferencePipeline\u0026#39;, MetricData=[ { \u0026#39;MetricName\u0026#39;: \u0026#39;LatencyMs\u0026#39;, \u0026#39;Value\u0026#39;: latency_ms, \u0026#39;Unit\u0026#39;: \u0026#39;Milliseconds\u0026#39; }, { \u0026#39;MetricName\u0026#39;: \u0026#39;SuccessCount\u0026#39; if success else \u0026#39;ErrorCount\u0026#39;, \u0026#39;Value\u0026#39;: 1, \u0026#39;Unit\u0026#39;: \u0026#39;Count\u0026#39; } ] ) # Gọi hàm này sau mỗi lần inference thành công publish_metrics(latency_ms, success=True) Namespace: tên nhóm metric (InferencePipeline). LatencyMs: thời gian xử lý inference. SuccessCount/ErrorCount: số lượt gọi thành công hoặc lỗi. 3. Tạo Dashboard theo dõi pipeline Truy cập CloudWatch → Dashboards → Create dashboard.\nĐặt tên: Inference-Monitoring-Dashboard.\nThêm các widget:\n📊 Metric graph: biểu đồ LatencyMs theo thời gian. 📈 Number: tổng số inference thành công (SuccessCount). ❌ Number: tổng số inference lỗi (ErrorCount). Dashboard giúp bạn theo dõi hiệu suất theo thời gian thực, hỗ trợ tối ưu mô hình và tài nguyên.\n4. Tạo Alarm cảnh báo tự động Để nhận cảnh báo khi hệ thống gặp sự cố:\nTruy cập CloudWatch → Alarms → Create alarm. Chọn metric: LatencyMs \u0026gt; 2000 ms (2 giây). Hoặc ErrorCount \u0026gt; 0. Cấu hình hành động: Gửi thông báo qua Amazon SNS (email, SMS). Đặt tên: High-Latency-Alarm hoặc Inference-Error-Alarm. 5. Kiểm tra toàn bộ luồng inference Gửi vài yêu cầu đến API inference. Kiểm tra: 📜 Log Lambda và SageMaker hiển thị đầy đủ. 📊 Dashboard hiển thị số lượng inference và độ trễ. 🚨 Alarm kích hoạt nếu vượt ngưỡng. Nếu không thấy metric hiển thị, kiểm tra quyền IAM của Lambda (cloudwatch:PutMetricData). Đảm bảo Lambda gửi metric sau mỗi lần inference. Kiểm tra múi giờ khi đọc dữ liệu dashboard.\n✅ Hoàn thành Bạn đã tích hợp và giám sát toàn bộ pipeline inference với Amazon CloudWatch. Hệ thống giờ đây có thể ghi log, đo hiệu suất, phát hiện lỗi sớm và gửi cảnh báo tự động. "
},
{
	"uri": "//localhost:1313/vi/10-conclusion/",
	"title": "Kết luận và những điểm chính",
	"tags": [],
	"description": "",
	"content": "📌 Tổng kết Workshop Chúc mừng bạn 🎉 – bạn đã hoàn thành toàn bộ workshop \u0026ldquo;Building an End-to-End Machine Learning Pipeline on AWS\u0026rdquo;!\nQua 9 chương trước, bạn đã tự tay xây dựng một hệ thống Machine Learning tự động – mở rộng – thực chiến từ đầu đến cuối, bao gồm:\nData Storage (S3) – lưu trữ dữ liệu đầu vào và output model. Lambda Functions – xử lý tiền xử lý (preprocessing) và suy luận (inference) mà không cần máy chủ. API Gateway – cung cấp RESTful API để kết nối model tới ứng dụng bên ngoài. SageMaker – huấn luyện, triển khai và quản lý model ML ở quy mô lớn. DynamoDB – lưu metadata, kết quả inference và log model. CloudWatch – giám sát, logging và tối ưu hiệu năng hệ thống. CloudFront – tăng tốc phân phối nội dung và bảo mật HTTPS cho ứng dụng. 🚀 Giá trị và Lợi ích Thực Tế Workshop này không chỉ là một bài học kỹ thuật – nó là một mô hình hoàn chỉnh cho các dự án AI/ML thực tế. Việc hiểu và triển khai pipeline như vậy sẽ giúp bạn:\n👨‍💻 Đối với Kỹ sư \u0026amp; Nhà phát triển: Xây dựng ML Pipeline thực chiến mà các công ty công nghệ đang dùng. Tự động hóa toàn bộ quy trình từ thu thập dữ liệu → huấn luyện → triển khai → inference. Không cần quản lý máy chủ (serverless) – tiết kiệm chi phí và dễ mở rộng. 🧪 Đối với sinh viên Nắm vững kiến trúc ML hiện đại trên đám mây – kỹ năng rất được yêu cầu trong thị trường việc làm. Hiểu sâu cách các dịch vụ AWS phối hợp với nhau trong một hệ thống AI hoàn chỉnh. 🧠 Kiến thức trọng tâm cần ghi nhớ Trong quá trình thực hành, bạn đã tiếp cận rất nhiều dịch vụ và khái niệm. Dưới đây là những kiến thức quan trọng nhất mà bạn cần nắm chắc:\nChủ đề Nội dung cốt lõi Vai trò trong hệ thống Amazon S3 Lưu trữ dữ liệu huấn luyện, mô hình và kết quả Nền tảng dữ liệu AWS Lambda Chạy code không cần máy chủ (preprocessing \u0026amp; inference) Xử lý dữ liệu và dự đoán Amazon SageMaker Huấn luyện và triển khai mô hình ML Trái tim của pipeline API Gateway Tạo API RESTful kết nối ứng dụng với model Giao tiếp với bên ngoài DynamoDB Lưu metadata, kết quả và thông tin model Quản lý dữ liệu phi cấu trúc CloudWatch Theo dõi log, hiệu năng và cảnh báo Quan sát và giám sát hệ thống IAM Cấp quyền truy cập an toàn giữa các dịch vụ Bảo mật và kiểm soát truy cập CloudFront Tăng tốc phân phối nội dung qua CDN Hiệu năng \u0026amp; bảo mật ứng dụng 🌍 Mở rộng và Ứng dụng Thực Tiễn Workshop này có thể là nền tảng cho nhiều ứng dụng AI/ML thực tế như:\n🔎 Phân loại hình ảnh / văn bản – bạn chỉ cần thay đổi mô hình huấn luyện trong SageMaker. 🧠 Dự đoán chuỗi thời gian – thu thập dữ liệu IoT vào S3, huấn luyện và triển khai mô hình dự đoán. 📊 Hệ thống gợi ý – lưu dữ liệu người dùng, huấn luyện model và phục vụ qua API Gateway. 📱 AI Backend cho ứng dụng di động/web – inference qua Lambda và API Gateway ở quy mô lớn. 🛠️ Tiếp theo nên học gì? Để nâng cao hơn kỹ năng sau workshop này, bạn có thể tìm hiểu thêm:\n🧬 CI/CD cho ML (MLOps) – tự động hóa huấn luyện, kiểm thử và triển khai model với CodePipeline hoặc Step Functions. 🛡️ AWS WAF \u0026amp; Shield – tăng cường bảo mật API và ứng dụng inference. 📈 Advanced Monitoring – dùng CloudWatch Dashboard hoặc Grafana để giám sát mô hình chi tiết. 📦 Containerization – đóng gói model trong Docker và triển khai bằng SageMaker hoặc ECS/EKS. 🏆 Kết luận cuối cùng Bằng cách hoàn thành workshop này, bạn không chỉ học cách kết nối các dịch vụ AWS lại với nhau, mà còn hiểu sâu toàn bộ vòng đời của một mô hình Machine Learning trong môi trường sản xuất – từ dữ liệu đến inference.\n🌟 Đây chính là nền tảng kỹ năng mà các kỹ sư ML, Data Engineer và Cloud Developer hiện đại cần phải có để xây dựng những hệ thống AI có thể triển khai trong thế giới thực.\n"
},
{
	"uri": "//localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]